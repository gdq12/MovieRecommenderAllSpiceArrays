{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import NMF\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "ratings=pd.read_csv('ml-latest-small/ratings.csv')\n",
    "movies=pd.read_csv('ml-latest-small/movies.csv')\n",
    "tags=pd.read_csv('ml-latest-small/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_cleanup(df, filter_name):\n",
    "    '''\n",
    "    Reassignes ratings to a 3 (to neuralize it) based on userId or movieId filter.\n",
    "    1. top25_users_neutralize: removes effect of the top 25% that gave their input\n",
    "    2. bottom75_users_neutralize: removes effect of the bottom 75% that gave their input\n",
    "    3. top25_voted_neutralize: removes effect of top25% voted on films **note: not their \n",
    "                                        rating but ones that recieved the most input**\n",
    "    4. rate4_5_neutralize: removes effect of films that were rated a 4 and 5 on average  \n",
    "    5. combo: combination of 2 and 3\n",
    "    '''\n",
    "    df1=df.copy()\n",
    "    \n",
    "    #respective userid and movieId identifiers\n",
    "    user_rate=pd.DataFrame(df1.groupby('userId')['rating'].count())\n",
    "    title_rate_count=pd.DataFrame(df1.groupby('movieId')['rating'].count())\n",
    "    title_rate_mean=pd.DataFrame(df1.groupby('movieId')['rating'].mean())\n",
    "    \n",
    "    #filters\n",
    "    top25_user=user_rate[user_rate['rating']>600].index\n",
    "    bottom75_user=user_rate[user_rate['rating']<600].index\n",
    "    top25_movies_voted=title_rate_count[title_rate_count['rating']>9].index\n",
    "    rate4_movies=title_rate_mean[title_rate_mean['rating']==4].index \n",
    "    rate5_movies=title_rate_mean[title_rate_mean['rating']==5].index\n",
    "    \n",
    "    #1\n",
    "    if filter_name == 'top25_users_neutralize':\n",
    "        df1.set_index('userId', inplace=True)\n",
    "        df1.loc[top25_user,'rating']=3 \n",
    "        df1.reset_index(inplace=True)\n",
    "    #2\n",
    "    if filter_name == 'bottom75_users_neutralize':\n",
    "        df1.set_index('userId', inplace=True)\n",
    "        df1.loc[bottom75_user,'rating']=3 \n",
    "        df1.reset_index(inplace=True)\n",
    "    #3\n",
    "    if filter_name == 'top25_voted_neutralize':    \n",
    "        df1.set_index('movieId', inplace=True)\n",
    "        df1.loc[top25_movies_voted, 'rating']=3\n",
    "        df1.reset_index(inplace=True)\n",
    "    #4\n",
    "    if filter_name == 'rate4_5_neutralize':\n",
    "        df1.set_index('movieId', inplace=True)\n",
    "        df1.loc[rate4_movies, 'rating']=3 \n",
    "        df1.loc[rate5_movies, 'rating']=3 \n",
    "        df1.reset_index(inplace=True)\n",
    "    #5\n",
    "    if filter_name == 'combo':\n",
    "        df1.set_index('userId', inplace=True)\n",
    "        df1.loc[bottom75_user,'rating']=3 \n",
    "        df1.reset_index(inplace=True)\n",
    "        df1.set_index('movieId', inplace=True)\n",
    "        df1.loc[top25_movies_voted, 'rating']=3\n",
    "        df1.reset_index(inplace=True)\n",
    "    return df1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_default=ratings.copy()\n",
    "ratings1=input_cleanup(ratings, 'top25_users_neutralize')\n",
    "ratings2=input_cleanup(ratings, 'bottom75_users_neutralize')\n",
    "ratings3=input_cleanup(ratings, 'top25_voted_neutralize')\n",
    "ratings4=input_cleanup(ratings, 'rate4_5_neutralize')\n",
    "ratings5=input_cleanup(ratings, 'combo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf_model(df, n_components=20):\n",
    "    '''\n",
    "    Build NMF model based on input data. Function works as:\n",
    "    1. reformats inout data so movieId are the columns, userId is the index and the values are the ratings\n",
    "    2. saves the number of movies from (1) for the recommender function\n",
    "    3. saves the movieId number from (1) for recommender function\n",
    "    4. converts object from (1) to an array\n",
    "    5. builds an NMF model based on the array from (4) with 20 components and fills all empty values with 3 (neutral)\n",
    "    6. extracts the movieId-rating mastrix from model for recommender function\n",
    "    '''\n",
    "    Rtrue=df.pivot(index='userId', columns='movieId', values='rating').fillna(3) \n",
    "    num_movies=Rtrue.shape[1]\n",
    "    movieId=Rtrue.columns\n",
    "    Rtrue=np.array(Rtrue)\n",
    "    model=NMF(n_components)\n",
    "    model.fit(Rtrue)\n",
    "    component1=model.components_\n",
    "    return num_movies, movieId, model, component1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdquiceno2/opt/anaconda3/envs/MovieRecommender20/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "num_movies_default, movieId_default, model_default, component_default=nmf_model(ratings_default)\n",
    "pickle.dump(model_default, open('model_default', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdquiceno2/opt/anaconda3/envs/MovieRecommender20/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "num_movies1, movieId1, model1, component1=nmf_model(ratings1)\n",
    "pickle.dump(model1, open('model1', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdquiceno2/opt/anaconda3/envs/MovieRecommender20/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "num_movies2, movieId2, model2, component2=nmf_model(ratings2)\n",
    "pickle.dump(model2, open('model2', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdquiceno2/opt/anaconda3/envs/MovieRecommender20/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "num_movies3, movieId3, model3, component3=nmf_model(ratings3)\n",
    "pickle.dump(model3, open('model3', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdquiceno2/opt/anaconda3/envs/MovieRecommender20/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "num_movies4, movieId4, model4, component4=nmf_model(ratings4)\n",
    "pickle.dump(model4, open('model4', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdquiceno2/opt/anaconda3/envs/MovieRecommender20/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "num_movies5, movieId5, model5, component5=nmf_model(ratings5)\n",
    "pickle.dump(model5, open('model5', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MovieRecommender20",
   "language": "python",
   "name": "movierecommender20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
